#!/usr/bin/env python

import sys
import os
import time
from urllib import parse as urlparse

class ParsedURL:
    def __init__(self, urlstring, scheme='', allow_fragments=True):
        self.scheme, self.netloc, path, self.parameters, query, self.fragment = urlparse.urlparse(urlparse.unquote(urlstring),
            scheme, allow_fragments)
        self.path = path.strip('/ ').split('/')
        self.query = urlparse.parse_qs(query, keep_blank_values=True)

    def __str__(self):
        query = '&'.join([(lambda k, v: k if len(v) == 1 and v[0] == '' else '{}={}'.format(k, '+'.join(v)))(k, v) for k, v in self.query.items()])
        path = '/'.join(self.path)
        return urlparse.unquote(urlparse.urlunparse((self.scheme, self.netloc, path,
            self.parameters, query, self.fragment)))
        #-- end ParsedURL.__str__
    #-- end class ParsedURL

def extract_url_duckduckgo(purl):
    target = purl.query['uddg'][0] or None
    if target is None:
        raise Exception('invalid url {}'.format(str(purl)))
    return ParsedURL(target)
    #-- end extract_url_duckduckgo

def extract_url_google(purl):
    target = purl.query['q'][0] or None
    if target is None:
        raise Exception('invalid url {}'.format(str(purl)))
    return ParsedURL(target)

def extract_url_instagram(purl):
    target = purl.query['u'][0] or None
    if target is None:
        raise Exception('invalid url {}'.format(str(purl)))
    return ParsedURL(target)

def extract_url_facebook(purl):
    target = purl.query['u'][0] or None
    if target is None:
        raise Exception('invalid url {}'.format(str(purl)))
    return ParsedURL(target)
    #-- end extract_url_facebook

def extract_url(purl):
    if purl.netloc.count('duckduckgo.com') > 0:
        return extract_url_duckduckgo(purl)
    elif purl.netloc.count('google.com') > 0:
        return extract_url_google(purl)
    elif purl.netloc.count('instagram.com') > 0:
        return extract_url_instagram(purl)
    elif purl.netloc.count('facebook.com') > 0:
        return extract_url_instagram(purl)
    return purl
    #-- end extract_url

CGI_FMT = '''Content-Type: text/html; charset=UTF-8
Server: cgi
Date: {date}
w3m-control: BACK
w3m-control: GOTO {url}
w3m-control: MESSAGE Redirecting to {url} ...

<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8" />
        <title>Redirecting to {url} ...</title>
    </head>
    <body>
        <h1>Redirecting to {url} ...</h1>
        <p>Click <a href=\"{url}\">here</a> if redirect fails.</p>
    </body>
</html>
'''

ERROR_FMT = '''HTTP/1.1 404 Error
Content-Type: text/html; charset=UTF-8
Server: cgi
Date: {date}

<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8" />
        <title>Error: {error}</title>
    </head>
    <h1>Search-Redir Error</h1>
    <p>{error}</p>
</html>
'''

CGI_URI = 'sredir://'

if __name__ == "__main__":
    datestr = time.strftime('%a, %d %b %Y %H:%M:%S GMT', time.gmtime())
    urlstr = os.getenv('QUERY_STRING')
    if urlstr is None:
        sys.stdout.write(ERROR_FMT.format(error='no url provided'))
        exit(0)
    urlstr = urlstr.replace(CGI_URI, '', 1)
    url = ParsedURL(urlstr)
    try:
        target = extract_url(url)
        sys.stdout.write(CGI_FMT.format(url=str(target), date=datestr))
    except Exception as err:
        sys.stdout.write(ERROR_FMT.format(error=err, date=datestr))
    #-- end main

